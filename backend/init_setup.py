"""
åˆå§‹åŒ–è„šæœ¬ - ç”¨äºé¢„ä¸‹è½½æ‰€æœ‰å¿…éœ€çš„æ¨¡å‹å’Œä¾èµ–
è¿è¡Œæ­¤è„šæœ¬ä»¥é¿å…é¦–æ¬¡è¿è¡Œæ—¶çš„è¶…æ—¶é—®é¢˜
"""
import os
import sys
from dotenv import load_dotenv

def check_env_file():
    """æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    print("=" * 60)
    print("æ­¥éª¤ 1: æ£€æŸ¥ç¯å¢ƒé…ç½®")
    print("=" * 60)
    
    if not os.path.exists(".env"):
        print("âš ï¸  æœªæ‰¾åˆ° .env æ–‡ä»¶")
        print("ğŸ“ è¯·å¤åˆ¶ .env.example ä¸º .env å¹¶å¡«å…¥ä½ çš„ API Key")
        print("\nç¤ºä¾‹å‘½ä»¤:")
        print("  Windows: copy .env.example .env")
        print("  Linux/Mac: cp .env.example .env")
        return False
    
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key or api_key == "sk-your-openai-api-key-here":
        print("âš ï¸  .env æ–‡ä»¶å­˜åœ¨ï¼Œä½† OPENAI_API_KEY æœªæ­£ç¡®é…ç½®")
        print("ğŸ“ è¯·ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥æœ‰æ•ˆçš„ API Key")
        return False
    
    print("âœ… ç¯å¢ƒé…ç½®æ£€æŸ¥é€šè¿‡")
    print(f"   - API Key: {api_key[:20]}...")
    print(f"   - Base URL: {os.getenv('OPENAI_BASE_URL', 'default')}")
    print(f"   - Model: {os.getenv('OPENAI_MODEL_NAME', 'gpt-3.5-turbo')}")
    return True

def download_chroma_models():
    """é¢„ä¸‹è½½ ChromaDB çš„åµŒå…¥æ¨¡å‹"""
    print("\n" + "=" * 60)
    print("æ­¥éª¤ 2: ä¸‹è½½ ChromaDB åµŒå…¥æ¨¡å‹")
    print("=" * 60)
    print("æ­£åœ¨ä¸‹è½½ ONNX MiniLM-L6-v2 æ¨¡å‹ï¼ˆçº¦ 80MBï¼‰...")
    print("è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...\n")
    
    try:
        import chromadb
        from chromadb.config import Settings
        
        # åˆ›å»ºä¸´æ—¶å®¢æˆ·ç«¯ä»¥è§¦å‘æ¨¡å‹ä¸‹è½½
        client = chromadb.Client(Settings(
            persist_directory="./chroma_db",
            is_persistent=True
        ))
        
        # åˆ›å»ºä¸´æ—¶é›†åˆä»¥è§¦å‘åµŒå…¥å‡½æ•°åˆå§‹åŒ–
        collection = client.get_or_create_collection(name="init_test")
        
        # æ·»åŠ ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£æ¥è§¦å‘æ¨¡å‹ä¸‹è½½
        collection.add(
            documents=["è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ï¼Œç”¨äºè§¦å‘ ChromaDB æ¨¡å‹ä¸‹è½½ã€‚"],
            metadatas=[{"type": "test"}],
            ids=["test_init"]
        )
        
        print("âœ… ChromaDB åµŒå…¥æ¨¡å‹ä¸‹è½½å®Œæˆ")
        
        # æ¸…ç†æµ‹è¯•é›†åˆ
        client.delete_collection("init_test")
        
    except Exception as e:
        print(f"âŒ ChromaDB æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
        print("ğŸ’¡ æç¤º: å¦‚æœæ˜¯ç½‘ç»œè¶…æ—¶ï¼Œå¯ä»¥:")
        print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("   2. ä½¿ç”¨ä»£ç†")
        print("   3. æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶")
        return False
    
    return True

def test_openai_connection():
    """æµ‹è¯• OpenAI API è¿æ¥"""
    print("\n" + "=" * 60)
    print("æ­¥éª¤ 3: æµ‹è¯• LLM è¿æ¥")
    print("=" * 60)
    
    try:
        from langchain_openai import ChatOpenAI
        from langchain_core.messages import HumanMessage
        
        llm = ChatOpenAI(
            model=os.getenv("OPENAI_MODEL_NAME", "gpt-3.5-turbo"),
            temperature=0.7,
            base_url=os.getenv("OPENAI_BASE_URL"),
            api_key=os.getenv("OPENAI_API_KEY"),
            timeout=30
        )
        
        print("æ­£åœ¨å‘é€æµ‹è¯•è¯·æ±‚...")
        response = llm.invoke([HumanMessage(content="Hello, say 'API Connected!'")])
        
        print("âœ… LLM è¿æ¥æˆåŠŸ")
        print(f"   å“åº”: {response.content[:100]}...")
        
    except Exception as e:
        print(f"âŒ LLM è¿æ¥å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥:")
        print("   1. API Key æ˜¯å¦æ­£ç¡®")
        print("   2. Base URL æ˜¯å¦å¯è®¿é—®")
        print("   3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        return False
    
    return True

def check_dependencies():
    """æ£€æŸ¥æ‰€æœ‰ä¾èµ–æ˜¯å¦å·²å®‰è£…"""
    print("\n" + "=" * 60)
    print("æ­¥éª¤ 4: æ£€æŸ¥ä¾èµ–åŒ…")
    print("=" * 60)
    
    required_packages = [
        "langgraph",
        "langchain",
        "langchain_openai",
        "chromadb",
        "chainlit",
        "openai",
        "dotenv"
    ]
    
    missing = []
    for package in required_packages:
        try:
            __import__(package.replace("-", "_"))
            print(f"âœ… {package}")
        except ImportError:
            print(f"âŒ {package} (æœªå®‰è£…)")
            missing.append(package)
    
    if missing:
        print(f"\nâš ï¸  ç¼ºå°‘ä¾èµ–: {', '.join(missing)}")
        print("è¯·è¿è¡Œ: pip install -r requirements.txt")
        return False
    
    print("\nâœ… æ‰€æœ‰ä¾èµ–åŒ…å·²å®‰è£…")
    return True

def main():
    print("\n" + "ğŸš€ " * 15)
    print("AI å°è¯´å†™ä½œæ¡†æ¶ - åˆå§‹åŒ–ç¨‹åº")
    print("ğŸš€ " * 15 + "\n")
    
    # æ­¥éª¤ 1: æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        print("\nâŒ åˆå§‹åŒ–å¤±è´¥: è¯·å…ˆå®‰è£…ä¾èµ–")
        sys.exit(1)
    
    # æ­¥éª¤ 2: æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not check_env_file():
        print("\nâŒ åˆå§‹åŒ–å¤±è´¥: è¯·é…ç½® .env æ–‡ä»¶")
        sys.exit(1)
    
    # æ­¥éª¤ 3: ä¸‹è½½ ChromaDB æ¨¡å‹
    if not download_chroma_models():
        print("\nâš ï¸  ChromaDB æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œä½†å¯ä»¥ç»§ç»­")
        print("   é¦–æ¬¡è¿è¡Œæ—¶å¯èƒ½ä¼šé‡è¯•ä¸‹è½½")
    
    # æ­¥éª¤ 4: æµ‹è¯• LLM è¿æ¥
    if not test_openai_connection():
        print("\nâš ï¸  LLM è¿æ¥æµ‹è¯•å¤±è´¥")
        print("   è¯·æ£€æŸ¥é…ç½®åå†è¿è¡Œä¸»ç¨‹åº")
    
    print("\n" + "=" * 60)
    print("âœ… åˆå§‹åŒ–å®Œæˆï¼")
    print("=" * 60)
    print("\nç°åœ¨å¯ä»¥è¿è¡Œä¸»ç¨‹åº:")
    print("  chainlit run app.py -w")
    print("\n" + "ğŸ‰ " * 15 + "\n")

if __name__ == "__main__":
    main()
